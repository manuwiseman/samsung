recent highlights

1. input/soft keyboard AR browser

Situation: We are developing a cutting-edge AR platform web browser, we provid web-engine part, we use unity, and we have a team helping us to develop the UI part in unity, we more focus on providing the web engine service. we also have microsoft as our partner to provide us lower level ARDK support, called CoreXP, we are trying to add a feature that supports soft keyboard in AR browser, and the soft keyboard should show up on the phone screen, as part of bigger concept "phone as controller"

Task: I was approached by my manager and one of my teammate for an urgent and important feature which is to support soft keyboard in the input box in our AR web browser, this is an important feature and has been working fine for our mobiel browser,  and it's hitting the same part of the logic in our web engien code. my teammate has been working on this issue for 2-3 weeks and has been stuck, he had a patch that added a lot of logging in the code, but what happened was mobile code and AR code did hit same part of logic, but for mobile browser the content view has an active input connection with the input manager, however, the same content view object doesn't have an active input connection with the input mananger. 

Action: I pulled in my teammate's patch and confirmed that I can reproduce the issue, I was also very confused about why the contenet view in AR code doesn't have an active input connection, one difference I know between the AR browser and the mobile browser is AR obviously has a separate display i.e. the headset, and when the AR browser is launched, right now it's a 2-step procedure, 1. on the phone click the app like every other android app, 2. on the phone it will show a page with blue button says "show app in HMD", and this is from microsoft coreXP. So what I suspect is maybe the content view is not the view that currently has the focus, so I put more logging and debug more, it turns out the view that has focus and can potentially have an active input connect is the unity surface view and that's the view that's showing that blue button "show app in HMD", so I added code in our web engine, to check if we are in AR web browser, then start the input connection with the unity surface view.

Once I tried that, the soft keyboard finally shows up successfully on the mobile phone screen, this is what we wanted because the requirement is to have the "phone as controller", however, when I tried to type it I found that the typing is not being displayed in the input box in the HMD. My teammate then insisted that we should try to somehow make the input connection active with the content view, and once we have that then the typing not being displayed issue in theory will be fixed. I then took a step back and thought thru how it should work, the view that has the active input connection is the unity surface view, and whatever we type right now is happening only in the unity side, I then put some debugger in the unity activity class and see the dispatchKeyEvent(), onKeyDown(), onKeyUp() method was called, I then realize all we need to do is somehow send this key event back to our web engine code, and that content view belongs to our web engine, once the web engine receives the key event, it will work just like mobile code. I explained my thoughts to my teammate and manager, they think this is pretty convincing (can also said that my teammate initially doesn't like this idea and said passing the key event might cause delay, etc, then I proved him wrong after I write up the patch and shows the working soft keyboard), I write up the patch quickly, and build the apk. And the soft keyboard works like a charm.

Result: we were able to solve this urgent issue and able to deliver a few days earlier than the deadline so the QA have more time to test it, so far the feedback about this feature is very good.